# 6.824_P15_Spark

前12节课的视频，建议参考翻译https://mit-public-courses-cn-translatio.gitbook.io/mit6-824/

这篇文章只是记录一些要点和自己的思考，有助于理解第15节课，但和之前的翻译相比，区别较大

Spark是一个围绕速度、易用性和复杂分析构件的大数据处理平台。

这节课程的前半部分，主要介绍了一个例子，我没有用过，也没有好好听。。。

## 容错

Spark中容错的概念跟数据库的容错不同，后者意味着数据不能丢、不能错，Spark容错意味着尽量不要重新开始全部计算。

Spark没有自己的分布式文件系统，一般假定给予HDFS，HDFS提供了输入文件的容错，确保输入不会丢、不会错。Spark负责后面计算部分的容错。

Spark中的某个Worker发生故障，但是它可能依赖很多其他节点（wide dependency)的输出，如果不加任何设计，其他节点完成计算后并不会保存输出，此时需要重新计算，每一个节点又依赖上一层节点的输出，重新计算的工作量很大，因此Spark设置了check point，对输出数据进行保留，重新计算时，从check point开始。

## Spark Streaming

Spark还是批处理，Spark Streaming是对Spark的扩展，将流数据转化为小的批数据，然后交给Spark处理。